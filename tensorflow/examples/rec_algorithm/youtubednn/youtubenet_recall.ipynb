{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83581486-43c6-4a0a-97d7-eac3ef72c0ae",
   "metadata": {},
   "source": [
    "## YouTubeNet 召回模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afca9838-75f9-4f7d-be00-559e4f98b975",
   "metadata": {},
   "source": [
    "## movielens 数据集处理\n",
    "数据处理方式与MIND算法一样。可参考MIND部分的数据处理结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14629c0a-c915-47bb-9c7f-6b3f5d4ddc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "input_dir = \"../../../data/ml-1m/\"\n",
    "output_dir = \"../../../data/ml-1m/mind/\"\n",
    "\n",
    "train_path = os.path.join(output_dir, \"train.txt\")\n",
    "test_path = os.path.join(output_dir, \"test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dad98b2-ea27-4ab0-9cff-e751dea7e634",
   "metadata": {},
   "source": [
    "### 模型结构定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb057324-18e1-4165-ba98-d53adba27699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Lambda, Layer\n",
    "\n",
    "\n",
    "class SequencePoolingLayer(Layer):\n",
    "\n",
    "    def __init__(self, mode=\"mean\", support_mask=True, sequence_mask_length=50, **kwargs):\n",
    "\n",
    "        if mode not in [\"mean\", \"max\", \"sum\"]:\n",
    "            raise ValueError(\"mode must be `mean`, `max` or `sum` !\")\n",
    "\n",
    "        self.mode = mode\n",
    "        self.eps = tf.constant(1e-8, tf.float32)\n",
    "        self.support_mask = support_mask\n",
    "        self.sequence_mask_length = sequence_mask_length\n",
    "\n",
    "        super(SequencePoolingLayer, self).__init__(**kwargs)\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(SequencePoolingLayer, self).build(input_shape)\n",
    "\n",
    "\n",
    "    def call(self, input_hist_seq_list, **kwargs):\n",
    "\n",
    "        hist_user_embedding_list, hist_user_behavior_length = input_hist_seq_list\n",
    "\n",
    "        if not self.support_mask:\n",
    "\n",
    "            if self.mode == \"max\":\n",
    "                return tf.reduce_max(hist_user_embedding_list, 1, keepdims=True)\n",
    "\n",
    "            mode_sum = tf.reduce_sum(hist_user_embedding_list, 1, keepdims=True)\n",
    "\n",
    "            if self.mode == \"sum\":\n",
    "                return mode_sum\n",
    "\n",
    "            if self.mode == \"mean\":\n",
    "                return tf.divide(mode_sum, self.sequence_mask_length + self.eps)\n",
    "\n",
    "\n",
    "        if self.support_mask:\n",
    "\n",
    "            # mask matrix\n",
    "            mask_list = tf.sequence_mask(hist_user_behavior_length, self.sequence_mask_length, dtype=tf.float32)\n",
    "\n",
    "            # transpose mask matrix\n",
    "            mask_transpose_list = tf.transpose(mask_list, (0, 2, 1))\n",
    "            embedding_dim = hist_user_embedding_list.shape[-1]\n",
    "\n",
    "            # expand mask matrix\n",
    "            mask_tile_list = tf.tile(mask_transpose_list, [1, 1, embedding_dim])\n",
    "\n",
    "\n",
    "            # max\n",
    "            if self.mode == \"max\":\n",
    "                hist = hist_user_embedding_list - (1-mask_tile_list) * 1e9\n",
    "                return tf.reduce_max(hist, 1, keepdims=True)\n",
    "\n",
    "\n",
    "            mode_sum = tf.reduce_sum(hist_user_embedding_list * mask_tile_list, 1, keepdims=True)\n",
    "\n",
    "            # sum\n",
    "            if self.mode == \"sum\":\n",
    "                return mode_sum\n",
    "\n",
    "            # mean\n",
    "            if self.mode == \"mean\":\n",
    "                hist_user_behavior_length = tf.reduce_sum(mask_list, axis=-1, keepdims=True)\n",
    "\n",
    "                return tf.divide(mode_sum, \\\n",
    "                    tf.cast(hist_user_behavior_length, tf.float32) + self.eps)\n",
    "\n",
    "            \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, 1, input_shape[0][-1])\n",
    "        \n",
    "        \n",
    "    def config(self):\n",
    "        config = {\"mode\": self.mode, \"support_mask\": self.support_mask, \\\n",
    "            \"sequence_mask_length\": self.sequence_mask_length}\n",
    "\n",
    "        base_config = super(SequencePoolingLayer, self).get_config()\n",
    "\n",
    "        return dict(list(base_config.items()) + list(config.items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebd5293c-380f-4371-acbb-dba9ce37da84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, concatenate, Dense, Dropout\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "def YouTubeNet(\n",
    "    sparse_input_length=1,\n",
    "    dense_input_length=1,\n",
    "    sparse_seq_input_length=50,\n",
    "    \n",
    "    embedding_dim = 64,\n",
    "    neg_sample_num = 10, \n",
    "    user_hidden_unit_list = [128, 64]\n",
    "    ):\n",
    "\n",
    "    # 1. Input layer\n",
    "    user_id_input_layer = Input(shape=(sparse_input_length, ), name=\"user_id_input_layer\")\n",
    "    gender_input_layer = Input(shape=(sparse_input_length, ), name=\"gender_input_layer\")\n",
    "    age_input_layer = Input(shape=(sparse_input_length, ), name=\"age_input_layer\")\n",
    "    occupation_input_layer = Input(shape=(sparse_input_length, ), name=\"occupation_input_layer\")\n",
    "    zip_input_layer = Input(shape=(sparse_input_length, ), name=\"zip_input_layer\")\n",
    "    \n",
    "    \n",
    "    user_click_item_seq_input_layer = Input(shape=(sparse_seq_input_length, ), name=\"user_click_item_seq_input_layer\")\n",
    "    user_click_item_seq_length_input_layer = Input(shape=(sparse_input_length, ), name=\"user_click_item_seq_length_input_layer\")\n",
    "    \n",
    "    \n",
    "    pos_item_sample_input_layer = Input(shape=(sparse_input_length, ), name=\"pos_item_sample_input_layer\")\n",
    "    neg_item_sample_input_layer = Input(shape=(neg_sample_num, ), name=\"neg_item_sample_input_layer\")\n",
    "\n",
    "\n",
    "    \n",
    "    # 2. Embedding layer\n",
    "    user_id_embedding_layer = Embedding(6040+1, embedding_dim, mask_zero=True, name='user_id_embedding_layer')(user_id_input_layer)\n",
    "    gender_embedding_layer = Embedding(2+1, embedding_dim, mask_zero=True, name='gender_embedding_layer')(gender_input_layer)\n",
    "    age_embedding_layer = Embedding(7+1, embedding_dim, mask_zero=True, name='age_embedding_layer')(age_input_layer)\n",
    "    occupation_embedding_layer = Embedding(21+1, embedding_dim, mask_zero=True, name='occupation_embedding_layer')(occupation_input_layer)\n",
    "    zip_embedding_layer = Embedding(3439+1, embedding_dim, mask_zero=True, name='zip_embedding_layer')(zip_input_layer)\n",
    "    \n",
    "    item_id_embedding_layer = Embedding(3706+1, embedding_dim, mask_zero=True, name='item_id_embedding_layer')\n",
    "    pos_item_sample_embedding_layer = item_id_embedding_layer(pos_item_sample_input_layer)\n",
    "    neg_item_sample_embedding_layer = item_id_embedding_layer(neg_item_sample_input_layer)\n",
    "    \n",
    "    user_click_item_seq_embedding_layer = item_id_embedding_layer(user_click_item_seq_input_layer)\n",
    "    #user_click_item_seq_embedding_layer = SequencePoolingLayer(sequence_mask_length=sparse_seq_input_length)\\\n",
    "    #    ([user_click_item_seq_embedding_layer, user_click_item_seq_length_input_layer])\n",
    "\n",
    "    user_click_item_seq_embedding_layer  = tf.reduce_mean(user_click_item_seq_embedding_layer, 1, keepdims=True)\n",
    "\n",
    "    \n",
    "\n",
    "    ### ********** ###\n",
    "    # user part\n",
    "    ### ********** ###\n",
    "\n",
    "    # 3. Concat \"sparse\" embedding & \"sparse_seq\" embedding\n",
    "    user_embedding_layer = concatenate([user_id_embedding_layer, gender_embedding_layer, age_embedding_layer,\n",
    "                                       occupation_embedding_layer, zip_embedding_layer, user_click_item_seq_embedding_layer], \n",
    "                                       axis=-1)\n",
    "\n",
    "\n",
    "    for i, u in enumerate(user_hidden_unit_list):\n",
    "        user_embedding_layer = Dense(u, activation=\"relu\", name=\"FC_{0}\".format(i+1))(user_embedding_layer)\n",
    "        #user_embedding_layer = Dropout(0.3)(user_embedding_layer)\n",
    "        \n",
    "    \n",
    "    ### ********** ###\n",
    "    # item part\n",
    "    ### ********** ###\n",
    "\n",
    "    item_embedding_layer = concatenate([pos_item_sample_embedding_layer, neg_item_sample_embedding_layer], \\\n",
    "                                       axis=1)\n",
    "    \n",
    "    item_embedding_layer = tf.transpose(item_embedding_layer, [0,2,1])\n",
    "    \n",
    "\n",
    "\n",
    "    # Output\n",
    "    dot_output = tf.matmul(user_embedding_layer, item_embedding_layer) \n",
    "    dot_output = tf.nn.softmax(dot_output) # 输出11个值，index为0的值是正样本，负样本的索引位置为[1-10]\n",
    "    \n",
    "    user_inputs_list = [user_id_input_layer, gender_input_layer, age_input_layer, \\\n",
    "                        occupation_input_layer, zip_input_layer, \\\n",
    "                        user_click_item_seq_input_layer, user_click_item_seq_length_input_layer]\n",
    "    \n",
    "    item_inputs_list = [pos_item_sample_input_layer, neg_item_sample_input_layer]\n",
    "\n",
    "    model = Model(inputs = user_inputs_list + item_inputs_list,\n",
    "                  outputs = dot_output)\n",
    "    \n",
    "    #print(model.summary())\n",
    "    #tf.keras.utils.plot_model(model, to_file='YouTubeNet_model.png', show_shapes=True)\n",
    "\n",
    "\n",
    "\n",
    "    model.__setattr__(\"user_input\", user_inputs_list)\n",
    "    model.__setattr__(\"user_embedding\", user_embedding_layer)\n",
    "    \n",
    "    model.__setattr__(\"item_input\", pos_item_sample_input_layer)\n",
    "    model.__setattr__(\"item_embedding\", pos_item_sample_embedding_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68bfa1e-c5bd-4f7c-bf03-4413811ae6d3",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff21bb4d-fdc4-4d3d-9cf7-d99595b090c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from data_generator import file_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ec7d82f-9efc-41d1-9a19-b39351eef21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_train:  988129\n",
      "n_val:  6040\n",
      "steps_per_epoch:  989\n",
      "validation_steps:  7\n"
     ]
    }
   ],
   "source": [
    "# 1. Load data\n",
    "\n",
    "train_path = train_path\n",
    "val_path =  test_path\n",
    "batch_size = 1000\n",
    "\n",
    "n_train = sum([1 for i in open(train_path)])\n",
    "n_val = sum([1 for i in open(val_path)])\n",
    "\n",
    "train_steps = n_train / batch_size\n",
    "train_steps_ = n_train // batch_size\n",
    "validation_steps = n_val / batch_size\n",
    "validation_steps_ = n_val // batch_size\n",
    "\n",
    "\n",
    "train_generator = file_generator(train_path, batch_size)\n",
    "val_generator = file_generator(val_path, batch_size)\n",
    "\n",
    "steps_per_epoch = train_steps_ if train_steps==train_steps_ else train_steps_ + 1\n",
    "validation_steps = validation_steps_ if validation_steps==validation_steps_ else validation_steps_ + 1\n",
    "\n",
    "print(\"n_train: \", n_train)\n",
    "print(\"n_val: \", n_val)\n",
    "\n",
    "print(\"steps_per_epoch: \", steps_per_epoch)\n",
    "print(\"validation_steps: \", validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d3d4ca7-c733-4b08-8b92-c6e57a31d9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "989/989 [==============================] - 64s 63ms/step - loss: 1.8195 - sparse_categorical_accuracy: 0.3474 - val_loss: 1.6834 - val_sparse_categorical_accuracy: 0.3863\n",
      "Epoch 2/2\n",
      "989/989 [==============================] - 191s 193ms/step - loss: 1.5092 - sparse_categorical_accuracy: 0.4359 - val_loss: 1.5929 - val_sparse_categorical_accuracy: 0.4204\n"
     ]
    }
   ],
   "source": [
    "# 2. Train model\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "callbacks = [early_stopping_cb]\n",
    "\n",
    "\n",
    "model = YouTubeNet()\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \\\n",
    "    optimizer=Adam(lr=1e-3), \\\n",
    "    metrics=['sparse_categorical_accuracy'])\n",
    "# loss=\"sparse_categorical_accuracy\"的应用方式参见：https://mp.weixin.qq.com/s/H4ET0bO_xPm8TNqltMt3Fg\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(train_generator, \\\n",
    "                    epochs=2, \\\n",
    "                    steps_per_epoch = steps_per_epoch, \\\n",
    "                    callbacks = callbacks,\n",
    "                    validation_data = val_generator, \\\n",
    "                    validation_steps = validation_steps, \\\n",
    "                    shuffle=True\n",
    "                   )\n",
    "\n",
    "\n",
    "\n",
    "model_path = \"../../../data/ml-1m/youtube/model/YouTubeNet_model.h5\"\n",
    "\n",
    "\n",
    "model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a493bb7b-cc15-4e01-93a4-5745ab31df60",
   "metadata": {},
   "source": [
    "#### 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e11cdaf8-89d5-49eb-96dc-8f9f579a1469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6040, 1, 64)\n",
      "(3707, 1, 64)\n",
      "[[3.7275229  0.77930844 0.         0.         0.         3.0729573\n",
      "  0.6435612  0.         0.         0.         0.         0.36303705\n",
      "  0.         0.         0.         0.         1.1476315  1.9882993\n",
      "  0.         0.51794946 1.6225233  0.8736892  0.7667916  0.\n",
      "  0.97278404 0.         0.9066596  0.39286005 0.         1.0374975\n",
      "  1.3326021  1.3058554  0.         1.1266472  1.0915216  1.4909037\n",
      "  3.4928114  0.91215193 0.         0.30906323 0.         2.2884986\n",
      "  0.         0.08073004 2.4222858  0.26510972 0.         0.08399317\n",
      "  0.5417748  1.5366259  0.         1.343622   2.1907806  0.\n",
      "  0.         2.3240263  0.         3.224169   0.         0.\n",
      "  1.44854    0.         0.5975563  0.        ]\n",
      " [0.         9.178487   1.9666482  0.         1.2365543  0.\n",
      "  0.2566222  2.4942667  1.0633035  1.7844172  0.         0.\n",
      "  0.         0.         0.76999754 5.2367306  0.         1.0767261\n",
      "  0.9573877  0.8556204  0.         0.         0.         0.41146037\n",
      "  0.         1.4084545  0.         0.         0.98739946 0.31472555\n",
      "  1.4952738  0.         0.         3.1617608  0.         0.\n",
      "  0.12617289 0.         0.         0.30739355 0.         0.42944127\n",
      "  3.355591   0.         0.         0.4734152  0.         1.0879644\n",
      "  1.168237   0.40639552 4.7787952  2.8841586  1.5165579  5.290321\n",
      "  0.6366241  0.         0.30199033 0.         0.42872533 0.04150064\n",
      "  0.         0.         0.8208278  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from data_generator import init_output\n",
    "\n",
    "\n",
    "# 1. Load model\n",
    "\n",
    "re_model = YouTubeNet()\n",
    "re_model.load_weights(model_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. Load data\n",
    "\n",
    "user_id, gender, age, occupation, zip, \\\n",
    "        hist_movie_id, hist_len, pos_movie_id, neg_movie_id = init_output()\n",
    "\n",
    "with open(val_path, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "\n",
    "        buf = line.strip().split('\\t')\n",
    "\n",
    "        user_id.append(int(buf[0]))\n",
    "        gender.append(int(buf[1]))\n",
    "        age.append(int(buf[2]))\n",
    "        occupation.append(int(buf[3]))\n",
    "        zip.append(int(buf[4]))\n",
    "        hist_movie_id.append(np.array([int(i) for i in buf[5].strip().split(\",\")]))\n",
    "        hist_len.append(int(buf[6]))\n",
    "        pos_movie_id.append(int(buf[7]))\n",
    "        \n",
    "\n",
    "user_id = np.array(user_id, dtype='int32')\n",
    "gender = np.array(gender, dtype='int32')\n",
    "age = np.array(age, dtype='int32')\n",
    "occupation = np.array(occupation, dtype='int32')\n",
    "zip = np.array(zip, dtype='int32')\n",
    "hist_movie_id = np.array(hist_movie_id, dtype='int32')\n",
    "hist_len = np.array(hist_len, dtype='int32')\n",
    "pos_movie_id = np.array(pos_movie_id, dtype='int32')\n",
    "\n",
    "\n",
    "\n",
    "# 3. Generate user features for testing and full item features for retrieval\n",
    "\n",
    "test_user_model_input = [user_id, gender, age, occupation, zip, hist_movie_id, hist_len]\n",
    "all_item_model_input = list(range(0, 3706+1))\n",
    "\n",
    "user_embedding_model = Model(inputs=re_model.user_input, outputs=re_model.user_embedding)\n",
    "item_embedding_model = Model(inputs=re_model.item_input, outputs=re_model.item_embedding)\n",
    "\n",
    "user_embs = user_embedding_model.predict(test_user_model_input)\n",
    "item_embs = item_embedding_model.predict(all_item_model_input, batch_size=2 ** 12)\n",
    "\n",
    "print(user_embs.shape)\n",
    "print(item_embs.shape)\n",
    "\n",
    "\n",
    "user_embs = np.reshape(user_embs, (-1, 64))\n",
    "item_embs = np.reshape(item_embs, (-1, 64))\n",
    "\n",
    "print(user_embs[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76da4eb7-e452-4c70-87f5-a88424130ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_tf26_cpu",
   "language": "python",
   "name": "py37_tf26_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
