{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b6041db-6fa3-49ac-993c-eb4c841f5315",
   "metadata": {},
   "source": [
    "# Tensorflow 中的乘法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1617aa-5bd0-4a29-83fe-f5516c38e2c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### tf.multiply(A, B) = `A * B` : 矩阵元素乘法(element-wise) \n",
    "`tf.multiply`和`*`一样，是两个tensor的元素相乘（element-wise操作)。要求如下： \n",
    "1. 两个tensor的数据类型相同， \n",
    "2. 两个tensor的维度相同。或经过扩纬和广播(只支持size为1的维度广播)操作后相同。\n",
    "包括3种情况：\n",
    "+ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0032478-98e7-4300-a4c8-09aab16b4ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0:0 (2, 3, 4)\n",
      "x1:0 (2, 3, 4)\n",
      "x2:0 (1, 3, 4)\n",
      "x3:0 (2, 1, 4)\n",
      "x4:0 (1, 1, 4)\n",
      "x5:0 (1, 1, 1)\n",
      "x6:0 (3, 4)\n",
      "x7:0 (4,)\n",
      "x8:0 (1,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def test_multiply():\n",
    "    A = 2\n",
    "    B = 3\n",
    "    C = 4\n",
    "    size = A * B * C\n",
    "    x0 = tf.Variable(np.random.randint(1, 9, size=A*B*C, dtype='int32').reshape([A, B,C]), name = 'x0', dtype=tf.int32)\n",
    "    x1 = tf.Variable(np.random.randint(1, 9, size=A*B*C, dtype='int32').reshape([A, B,C]), name = 'x1',dtype=tf.int32)\n",
    "    x2 = tf.Variable(np.random.randint(1, 9, size=1*B*C, dtype='int32').reshape([1, B,C]), name = 'x2', dtype=tf.int32)\n",
    "    x3 = tf.Variable(np.random.randint(1, 9, size=A*1*C, dtype='int32').reshape([A, 1,C]), name = 'x3',dtype=tf.int32)\n",
    "    x4 = tf.Variable(np.random.randint(1, 9, size=1*1*C, dtype='int32').reshape([1, 1,C]), name = 'x4',dtype=tf.int32)\n",
    "    x5 = tf.Variable(np.random.randint(1, 9, size=1*1*1, dtype='int32').reshape([1, 1,1]), name = 'x5',dtype=tf.int32)\n",
    "    x6 = tf.Variable(np.random.randint(1, 9, size=B*C, dtype='int32').reshape([B,C]), name = 'x6',dtype=tf.int32)\n",
    "    x7 = tf.Variable(np.random.randint(1, 9, size=C, dtype='int32').reshape([C]), name = 'x7',dtype=tf.int32)\n",
    "    x8 = tf.Variable(np.random.randint(1, 9, size=1, dtype='int32').reshape([1]), name = 'x8',dtype=tf.int32)\n",
    "    y1 = tf.multiply(x0, x1, name = 'y1')\n",
    "    y2 = tf.multiply(x0, x2, name = 'y2')\n",
    "    y3 = tf.multiply(x0, x3, name = 'y3')\n",
    "    y4 = tf.multiply(x0, x4, name = 'y4')\n",
    "    y5 = tf.multiply(x0, x5, name = 'y5')\n",
    "    y6 = tf.multiply(x0, x6, name = 'y6')\n",
    "    y7 = tf.multiply(x0, x7, name = 'y7')\n",
    "    y8 = tf.multiply(x0, x8, name = 'y8')\n",
    "    print(x0.name,x0.shape)\n",
    "    print(x1.name,x1.shape)\n",
    "    print(x2.name,x2.shape)\n",
    "    print(x3.name,x3.shape)\n",
    "    print(x4.name,x4.shape)\n",
    "    print(x5.name,x5.shape)\n",
    "    print(x6.name,x6.shape)\n",
    "    print(x7.name,x7.shape)\n",
    "    print(x8.name,x8.shape)\n",
    "    \n",
    "    #print(x0)\n",
    "    #print(x1)\n",
    "    #print(x2)\n",
    "    #print(x3)\n",
    "    #print(x4)\n",
    "    #print(x5)\n",
    "    #print(x6)\n",
    "    #print(x7)\n",
    "    #print(x8)\n",
    "    #print('y1: ',y1)\n",
    "    #print('y2: ',y2)\n",
    "    #print('y3: ',y3)\n",
    "    #print('y4: ',y4)\n",
    "    #print('y5: ',y5)\n",
    "    #print('y6: ',y6)\n",
    "    #print('y7: ',y7)\n",
    "    #print('y8: ',y8)\n",
    "    \n",
    "test_multiply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ab891e-8a5d-42f9-a3e1-332f7815e5e3",
   "metadata": {},
   "source": [
    "#### tf.matmul(A, B)\n",
    "`tf.matmul` 是矩阵乘法。 A,B 的最后两维进行进行矩阵乘法运算。 要求是：1， 矩阵A，B的数据类型相同。2，矩阵A，B的最后两维满足满足矩阵乘法的要求。其余维度不相同时，会先进行扩纬然后对应维度广播使两者shape相同。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d5d3b8-eacb-471a-90fc-b75b69cb4931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bab1faa-222c-49e0-b3af-54383f4668f6",
   "metadata": {},
   "source": [
    "#### tf.tensordot( a, b,axes,name=None)\n",
    "`tf.tensordot` 也称为张量收缩。是指定特定轴的矩阵相乘。通过参数axes指定轴，两个tensor沿着指定轴进行张量收缩。收缩方式是矩阵乘法求和，或者理解为矩阵平铺成一维向量内积求和。\n",
    "这里参数axes有两种形式：\n",
    "+ axes参数是一个数值n，表示a的后n维形成的矩阵和b的前n维形成的矩阵，平铺成一维向量后做内积。弱axes=0,则表示两个tensor进行外积。\n",
    "+ axes的参数是两个list, 表示a在指定维度形成的矩阵和b在指定维度形成的矩阵，分平铺成一维向量后做内积；内积值则为结果tensor对应位置的值。\n",
    "下面是一些\n",
    "| tensor X1 shape | tensor X2 shape | axes             | 要求                                                  | 结果shape |\n",
    "| --------------- | --------------- | ---------------- | ------------------------------------------------------- | --------- |\n",
    "| [2,4,6]         | [9,4,6]         | ([2],[2])        | X1第2维值=X2第2维值                               | [2,4,9,4] |\n",
    "| [2,4,6]         | [9,4,6]         | ([1,2],[1,2])    | X1第1维和第2维的值连乘=X2的第1维和第2维值连乘(4*6=4*6) | [2, 9]    |\n",
    "| [2,4,6]         | [4,6,9]         | ([1,2],[0,1])    | X1第1维和第2维的值连乘=X2的第0维和第1维值连乘(4*6=4*6) | [2,9]     |\n",
    "| [2,4,6]         | [4,3,6,9]       | ([1,2],[0,2])    | X1第1维和第2维的值连乘=X2的第0维和第2维值连乘(4*6=4*6) | [2,3,9]   |\n",
    "| [2,4,6]         | [4,6]           | 2或([1,2],[0,1]) | X1第1维和第2维的值连乘=X2的第0维和第1维值连乘(4*6=4*6) | [2]       |\n",
    "| [2,4,6]         | [9,2,12]        | ([1,2],[1,2])    | X1第1维和第2维的值连乘=X2的第1维和第2维值连乘(4*6=1*12) | [2,9]     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e572a42-4539-478a-8911-5d2420952495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'x0:0' shape=(2, 3, 2) dtype=int32, numpy=\n",
      "array([[[7, 7],\n",
      "        [6, 8],\n",
      "        [5, 4]],\n",
      "\n",
      "       [[1, 2],\n",
      "        [1, 2],\n",
      "        [8, 6]]], dtype=int32)>\n",
      "<tf.Variable 'x1:0' shape=(2, 3, 4, 5) dtype=int32, numpy=\n",
      "array([[[[5, 3, 4, 1, 3],\n",
      "         [3, 2, 1, 3, 7],\n",
      "         [7, 7, 5, 3, 7],\n",
      "         [3, 6, 8, 8, 5]],\n",
      "\n",
      "        [[5, 5, 4, 3, 7],\n",
      "         [7, 1, 7, 7, 2],\n",
      "         [8, 4, 5, 6, 6],\n",
      "         [3, 4, 3, 4, 1]],\n",
      "\n",
      "        [[6, 8, 1, 2, 4],\n",
      "         [1, 8, 5, 6, 7],\n",
      "         [4, 7, 1, 2, 5],\n",
      "         [8, 4, 7, 4, 4]]],\n",
      "\n",
      "\n",
      "       [[[5, 6, 8, 2, 5],\n",
      "         [3, 3, 7, 3, 7],\n",
      "         [4, 1, 6, 4, 2],\n",
      "         [7, 8, 4, 4, 3]],\n",
      "\n",
      "        [[7, 5, 5, 7, 4],\n",
      "         [1, 2, 6, 3, 8],\n",
      "         [3, 5, 4, 4, 7],\n",
      "         [1, 8, 5, 7, 8]],\n",
      "\n",
      "        [[1, 6, 5, 8, 7],\n",
      "         [1, 1, 7, 5, 7],\n",
      "         [7, 1, 5, 2, 6],\n",
      "         [5, 8, 7, 2, 1]]]], dtype=int32)>\n",
      "tf.Tensor(\n",
      "[[[[[ 95  91  57  35  83]\n",
      "    [ 68  60  74  93  96]\n",
      "    [117 108  70  67 110]\n",
      "    [ 79  86 109 100  61]]\n",
      "\n",
      "   [[ 82 102 111  96  94]\n",
      "    [ 32  38 120  64 132]\n",
      "    [ 81  42  91  62  86]\n",
      "    [ 80 144  93  80  74]]]\n",
      "\n",
      "\n",
      "  [[[ 99  93  64  39  93]\n",
      "    [ 81  54  83 101  93]\n",
      "    [129 109  79  77 117]\n",
      "    [ 77  90 108 104  59]]\n",
      "\n",
      "   [[ 95 106 116 102  95]\n",
      "    [ 33  41 125  65 141]\n",
      "    [ 80  51  94  68  94]\n",
      "    [ 77 152  96  92  89]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[ 58  72  16  20  42]\n",
      "    [ 18  67  48  58  65]\n",
      "    [ 47  67  18  25  53]\n",
      "    [ 70  42  67  44  38]]\n",
      "\n",
      "   [[ 20  59  53  73  65]\n",
      "    [ 12  13  69  46  71]\n",
      "    [ 63  14  50  24  57]\n",
      "    [ 48  80  65  27  19]]]\n",
      "\n",
      "\n",
      "  [[[ 56  64  22  20  44]\n",
      "    [ 26  54  46  56  60]\n",
      "    [ 54  64  26  30  56]\n",
      "    [ 60  44  64  48  36]]\n",
      "\n",
      "   [[ 30  58  56  66  60]\n",
      "    [ 14  16  68  42  72]\n",
      "    [ 56  18  50  28  54]\n",
      "    [ 46  80  60  34  28]]]]], shape=(2, 2, 2, 4, 5), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def test_tensordot():\n",
    "    x0 = tf.Variable(np.random.randint(1, 9, size=2*4*6, dtype='int32').reshape([2, 4, 6]), name = 'x0', dtype=tf.int32)\n",
    "    x1 = tf.Variable(np.random.randint(1, 9, size=9*4*6, dtype='int32').reshape([9, 4, 6]), name = 'x1',dtype=tf.int32)\n",
    "    x2 = tf.Variable(np.random.randint(1, 9, size=4*6*9, dtype='int32').reshape([4, 6,9]), name = 'x2', dtype=tf.int32)\n",
    "    x3 = tf.Variable(np.random.randint(1, 9, size=4*3*6*9, dtype='int32').reshape([4,3,6,9]), name = 'x3',dtype=tf.int32)\n",
    "    x4 = tf.Variable(np.random.randint(1, 9, size=4*6, dtype='int32').reshape([4,6]), name = 'x4',dtype=tf.int32)\n",
    "    x5 = tf.Variable(np.random.randint(1, 9, size=9*2*12, dtype='int32').reshape([9, 2,12]), name = 'x5',dtype=tf.int32)\n",
    "    y11 = tf.tensordot(x0, x1, axes=([2], [2]))\n",
    "    y12 = tf.tensordot(x0, x1, axes=([1,2], [1,2]))\n",
    "    y2 = tf.tensordot(x0, x2, axes=([1, 2], [0, 1]))\n",
    "    y3 = tf.tensordot(x0, x3, axes=([1, 2], [0, 2]))\n",
    "    y4= tf.tensordot(x0, x4, axes=([1, 2], [0, 1]))\n",
    "    y5 = tf.tensordot(x0, x5, axes=([1, 2], [1, 2]))\n",
    "    \n",
    "    \n",
    "\n",
    "  \n",
    "    \n",
    "    #print(x0.name,x0.shape)\n",
    "    #print(x1.name,x1.shape)\n",
    "    #print(x2.name,x2.shape)\n",
    "    #print(x3.name,x3.shape)\n",
    "    #print(x4.name,x4.shape)\n",
    "    #print(x5.name,x5.shape)\n",
    "    #print('y11: ',y11.shape)\n",
    "    #print('y12: ',y12.shape)\n",
    "    #print('y2: ',y2.shape)\n",
    "    #print('y3: ',y3.shape)\n",
    "    #print('y4: ',y4.shape)\n",
    "    #print('y5: ',y5.shape)\n",
    "\n",
    "    #print(x0)\n",
    "    #print(x1)\n",
    "    #print(x2)\n",
    "    #print(x3)\n",
    "    #print(x4)\n",
    "    #print(x5)\n",
    "    #print('y11: ',y11)\n",
    "    #print('y12: ',y12)\n",
    "\n",
    "    #print('y2: ',y2)\n",
    "    #print('y3: ',y3)\n",
    "    #print('y4: ',y4)\n",
    "    #print('y5: ',y5)\n",
    "    #print('y6: ',y6)\n",
    "    #print('y7: ',y7)\n",
    "    #print('y8: ',y8)\n",
    "    \n",
    "    x6 = tf.Variable(np.random.randint(1, 9, size=2*3*2, dtype='int32').reshape([2, 3,2]), name = 'x0', dtype=tf.int32)\n",
    "    x7 = tf.Variable(np.random.randint(1, 9, size=2*3*4*5, dtype='int32').reshape([2, 3,4,5]), name = 'x1',dtype=tf.int32)\n",
    "\n",
    "    y67 = tf.tensordot(x6, x7, axes=([1],[1]))\n",
    "\n",
    "    print(x6)\n",
    "    print(x7)\n",
    "    print(y67)\n",
    "\n",
    "    \n",
    "test_tensordot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3453e343-03c5-41d7-9c92-a2afc18c778a",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_tf26_cpu",
   "language": "python",
   "name": "py37_tf26_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
