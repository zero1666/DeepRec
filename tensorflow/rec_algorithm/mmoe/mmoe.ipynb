{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc5681db-49ad-47cc-b788-a7f395c608af",
   "metadata": {},
   "source": [
    "## MMoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b56d4f1f-2a72-494d-aa92-1cbc71216aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import VarianceScaling\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import activations, initializers, regularizers, constraints\n",
    "from tensorflow.keras.layers import Layer, InputSpec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b258393-6aae-4fdc-92af-bc953d9c467c",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57cbbaa0-8239-42d1-bf7a-aa0e60a07dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "# Fix numpy seed for reproducibility\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "random.seed(SEED)\n",
    "\n",
    "# Fix TensorFlow graph-level seed for reproducibility\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "def data_preparation():\n",
    "    # The column names are from\n",
    "    # https://www2.1010data.com/documentationcenter/prod/Tutorials/MachineLearningExamples/CensusIncomeDataSet.html\n",
    "    column_names = ['age', 'class_worker', 'det_ind_code', 'det_occ_code', 'education', 'wage_per_hour', 'hs_college',\n",
    "                    'marital_stat', 'major_ind_code', 'major_occ_code', 'race', 'hisp_origin', 'sex', 'union_member',\n",
    "                    'unemp_reason', 'full_or_part_emp', 'capital_gains', 'capital_losses', 'stock_dividends',\n",
    "                    'tax_filer_stat', 'region_prev_res', 'state_prev_res', 'det_hh_fam_stat', 'det_hh_summ',\n",
    "                    'instance_weight', 'mig_chg_msa', 'mig_chg_reg', 'mig_move_reg', 'mig_same', 'mig_prev_sunbelt',\n",
    "                    'num_emp', 'fam_under_18', 'country_father', 'country_mother', 'country_self', 'citizenship',\n",
    "                    'own_or_self', 'vet_question', 'vet_benefits', 'weeks_worked', 'year', 'income_50k']\n",
    "\n",
    "    # Load the dataset in Pandas\n",
    "    train_df = pd.read_csv(\n",
    "        '../../../data/mmoe_data/census-income.data.gz',\n",
    "        delimiter=',',\n",
    "        header=None,\n",
    "        index_col=None,\n",
    "        names=column_names\n",
    "    )\n",
    "    other_df = pd.read_csv(\n",
    "        '../../../data/mmoe_data/census-income.test.gz',\n",
    "        delimiter=',',\n",
    "        header=None,\n",
    "        index_col=None,\n",
    "        names=column_names\n",
    "    )\n",
    "    # print('train_df', train_df.shape, train_df.head())\n",
    "    print('train_df',type(train_df), train_df.shape)\n",
    "    print('other_df',type(other_df), other_df.shape)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # First group of tasks according to the paper\n",
    "    label_columns = ['income_50k', 'marital_stat']\n",
    "\n",
    "    # One-hot encoding categorical columns\n",
    "    categorical_columns = ['class_worker', 'det_ind_code', 'det_occ_code', 'education', 'hs_college', 'major_ind_code',\n",
    "                           'major_occ_code', 'race', 'hisp_origin', 'sex', 'union_member', 'unemp_reason',\n",
    "                           'full_or_part_emp', 'tax_filer_stat', 'region_prev_res', 'state_prev_res', 'det_hh_fam_stat',\n",
    "                           'det_hh_summ', 'mig_chg_msa', 'mig_chg_reg', 'mig_move_reg', 'mig_same', 'mig_prev_sunbelt',\n",
    "                           'fam_under_18', 'country_father', 'country_mother', 'country_self', 'citizenship',\n",
    "                           'vet_question']\n",
    "    train_raw_labels = train_df[label_columns]\n",
    "    other_raw_labels = other_df[label_columns]\n",
    "    transformed_train = pd.get_dummies(train_df.drop(label_columns, axis=1), columns=categorical_columns)\n",
    "    transformed_other = pd.get_dummies(other_df.drop(label_columns, axis=1), columns=categorical_columns)\n",
    "    #print('transformed_other', transformed_other.shape, transformed_other.head())\n",
    "\n",
    "\n",
    "    # Filling the missing column in the other set\n",
    "    transformed_other['det_hh_fam_stat_ Grandchild <18 ever marr not in subfamily'] = 0\n",
    "    #print('transformed_train', transformed_other.shape, transformed_other.head())\n",
    "\n",
    "\n",
    "    # One-hot encoding categorical labels\n",
    "    train_income = to_categorical((train_raw_labels.income_50k == ' 50000+.').astype(int), num_classes=2)\n",
    "    train_marital = to_categorical((train_raw_labels.marital_stat == ' Never married').astype(int), num_classes=2)\n",
    "    other_income = to_categorical((other_raw_labels.income_50k == ' 50000+.').astype(int), num_classes=2)\n",
    "    other_marital = to_categorical((other_raw_labels.marital_stat == ' Never married').astype(int), num_classes=2)\n",
    "    #print('train_income', train_income.shape, train_income)\n",
    "\n",
    "\n",
    "    dict_outputs = {\n",
    "        'income': train_income.shape[1],\n",
    "        'marital': train_marital.shape[1]\n",
    "    }\n",
    "    dict_train_labels = {\n",
    "        'income': train_income,\n",
    "        'marital': train_marital\n",
    "    }\n",
    "    dict_other_labels = {\n",
    "        'income': other_income,\n",
    "        'marital': other_marital\n",
    "    }\n",
    "    output_info = [(dict_outputs[key], key) for key in sorted(dict_outputs.keys())]\n",
    "    #print('output_info', len(train_income), train_income[0])\n",
    "\n",
    "\n",
    "    # Split the other dataset into 1:1 validation to test according to the paper\n",
    "    validation_indices = transformed_other.sample(frac=0.5, replace=False, random_state=SEED).index\n",
    "    test_indices = list(set(transformed_other.index) - set(validation_indices))\n",
    "    validation_data = transformed_other.iloc[validation_indices]\n",
    "    validation_label = [dict_other_labels[key][validation_indices] for key in sorted(dict_other_labels.keys())]\n",
    "    test_data = transformed_other.iloc[test_indices]\n",
    "    test_label = [dict_other_labels[key][test_indices] for key in sorted(dict_other_labels.keys())]\n",
    "    train_data = transformed_train\n",
    "    train_label = [dict_train_labels[key] for key in sorted(dict_train_labels.keys())]\n",
    "\n",
    "    return train_data, train_label, validation_data, validation_label, test_data, test_label, output_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84f8fbc7-581d-4782-a773-cddd62615263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple callback to print out ROC-AUC\n",
    "class ROCCallback(Callback):\n",
    "    def __init__(self, training_data, validation_data, test_data):\n",
    "        self.train_X = training_data[0]\n",
    "        self.train_Y = training_data[1]\n",
    "        self.validation_X = validation_data[0]\n",
    "        self.validation_Y = validation_data[1]\n",
    "        self.test_X = test_data[0]\n",
    "        self.test_Y = test_data[1]\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        train_prediction = self.model.predict(self.train_X)\n",
    "        validation_prediction = self.model.predict(self.validation_X)\n",
    "        test_prediction = self.model.predict(self.test_X)\n",
    "\n",
    "        # Iterate through each task and output their ROC-AUC across different datasets\n",
    "        for index, output_name in enumerate(self.model.output_names):\n",
    "            train_roc_auc = roc_auc_score(self.train_Y[index], train_prediction[index])\n",
    "            validation_roc_auc = roc_auc_score(self.validation_Y[index], validation_prediction[index])\n",
    "            test_roc_auc = roc_auc_score(self.test_Y[index], test_prediction[index])\n",
    "            print(\n",
    "                'ROC-AUC-{}-Train: {} ROC-AUC-{}-Validation: {} ROC-AUC-{}-Test: {}'.format(\n",
    "                    output_name, round(train_roc_auc, 4),\n",
    "                    output_name, round(validation_roc_auc, 4),\n",
    "                    output_name, round(test_roc_auc, 4)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e0a06f-48ff-4804-b6f6-4b0fec87b87f",
   "metadata": {},
   "source": [
    "#### 模型结构定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4df3c710-3340-4667-91f7-c263c2d561bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMoE(Layer):\n",
    "    \"\"\"\n",
    "    Multi-gate Mixture-of-Experts model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 units,\n",
    "                 num_experts,\n",
    "                 num_tasks,\n",
    "                 use_expert_bias=True,\n",
    "                 use_gate_bias=True,\n",
    "                 expert_activation='relu',\n",
    "                 gate_activation='softmax',\n",
    "                 expert_bias_initializer='zeros',\n",
    "                 gate_bias_initializer='zeros',\n",
    "                 expert_bias_regularizer=None,\n",
    "                 gate_bias_regularizer=None,\n",
    "                 expert_bias_constraint=None,\n",
    "                 gate_bias_constraint=None,\n",
    "                 expert_kernel_initializer='VarianceScaling',\n",
    "                 gate_kernel_initializer='VarianceScaling',\n",
    "                 expert_kernel_regularizer=None,\n",
    "                 gate_kernel_regularizer=None,\n",
    "                 expert_kernel_constraint=None,\n",
    "                 gate_kernel_constraint=None,\n",
    "                 activity_regularizer=None,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "         Method for instantiating MMoE layer.\n",
    "        :param units: Number of hidden units\n",
    "        :param num_experts: Number of experts\n",
    "        :param num_tasks: Number of tasks\n",
    "        :param use_expert_bias: Boolean to indicate the usage of bias in the expert weights\n",
    "        :param use_gate_bias: Boolean to indicate the usage of bias in the gate weights\n",
    "        :param expert_activation: Activation function of the expert weights\n",
    "        :param gate_activation: Activation function of the gate weights\n",
    "        :param expert_bias_initializer: Initializer for the expert bias\n",
    "        :param gate_bias_initializer: Initializer for the gate bias\n",
    "        :param expert_bias_regularizer: Regularizer for the expert bias\n",
    "        :param gate_bias_regularizer: Regularizer for the gate bias\n",
    "        :param expert_bias_constraint: Constraint for the expert bias\n",
    "        :param gate_bias_constraint: Constraint for the gate bias\n",
    "        :param expert_kernel_initializer: Initializer for the expert weights\n",
    "        :param gate_kernel_initializer: Initializer for the gate weights\n",
    "        :param expert_kernel_regularizer: Regularizer for the expert weights\n",
    "        :param gate_kernel_regularizer: Regularizer for the gate weights\n",
    "        :param expert_kernel_constraint: Constraint for the expert weights\n",
    "        :param gate_kernel_constraint: Constraint for the gate weights\n",
    "        :param activity_regularizer: Regularizer for the activity\n",
    "        :param kwargs: Additional keyword arguments for the Layer class\n",
    "        \"\"\"\n",
    "        # Hidden nodes parameter\n",
    "        self.units = units\n",
    "        self.num_experts = num_experts\n",
    "        self.num_tasks = num_tasks\n",
    "\n",
    "        # Weight parameter\n",
    "        self.expert_kernels = None\n",
    "        self.gate_kernels = None\n",
    "        self.expert_kernel_initializer = initializers.get(expert_kernel_initializer)\n",
    "        self.gate_kernel_initializer = initializers.get(gate_kernel_initializer)\n",
    "        self.expert_kernel_regularizer = regularizers.get(expert_kernel_regularizer)\n",
    "        self.gate_kernel_regularizer = regularizers.get(gate_kernel_regularizer)\n",
    "        self.expert_kernel_constraint = constraints.get(expert_kernel_constraint)\n",
    "        self.gate_kernel_constraint = constraints.get(gate_kernel_constraint)\n",
    "\n",
    "        # Activation parameter\n",
    "        self.expert_activation = activations.get(expert_activation)\n",
    "        self.gate_activation = activations.get(gate_activation)\n",
    "\n",
    "        # Bias parameter\n",
    "        self.expert_bias = None\n",
    "        self.gate_bias = None\n",
    "        self.use_expert_bias = use_expert_bias\n",
    "        self.use_gate_bias = use_gate_bias\n",
    "        self.expert_bias_initializer = initializers.get(expert_bias_initializer)\n",
    "        self.gate_bias_initializer = initializers.get(gate_bias_initializer)\n",
    "        self.expert_bias_regularizer = regularizers.get(expert_bias_regularizer)\n",
    "        self.gate_bias_regularizer = regularizers.get(gate_bias_regularizer)\n",
    "        self.expert_bias_constraint = constraints.get(expert_bias_constraint)\n",
    "        self.gate_bias_constraint = constraints.get(gate_bias_constraint)\n",
    "\n",
    "        # Activity parameter\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "\n",
    "        # Keras parameter\n",
    "        self.input_spec = InputSpec(min_ndim=2)\n",
    "        self.supports_masking = True\n",
    "\n",
    "        super(MMoE, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "        Method for creating the layer weights.\n",
    "        :param input_shape: Keras tensor (future input to layer)\n",
    "                            or list/tuple of Keras tensors to reference\n",
    "                            for weight shape computations\n",
    "        \"\"\"\n",
    "        assert input_shape is not None and len(input_shape) >= 2\n",
    "\n",
    "        input_dimension = input_shape[-1]\n",
    "\n",
    "        # Initialize expert weights (number of input features * number of units per expert * number of experts)\n",
    "        self.expert_kernels = self.add_weight(\n",
    "            name='expert_kernel',\n",
    "            shape=(input_dimension, self.units, self.num_experts),\n",
    "            initializer=self.expert_kernel_initializer,\n",
    "            regularizer=self.expert_kernel_regularizer,\n",
    "            constraint=self.expert_kernel_constraint,\n",
    "        )\n",
    "\n",
    "        # Initialize expert bias (number of units per expert * number of experts)\n",
    "        if self.use_expert_bias:\n",
    "            self.expert_bias = self.add_weight(\n",
    "                name='expert_bias',\n",
    "                shape=(self.units, self.num_experts),\n",
    "                initializer=self.expert_bias_initializer,\n",
    "                regularizer=self.expert_bias_regularizer,\n",
    "                constraint=self.expert_bias_constraint,\n",
    "            )\n",
    "\n",
    "        # Initialize gate weights (number of input features * number of experts * number of tasks)\n",
    "        self.gate_kernels = [self.add_weight(\n",
    "            name='gate_kernel_task_{}'.format(i),\n",
    "            shape=(input_dimension, self.num_experts),\n",
    "            initializer=self.gate_kernel_initializer,\n",
    "            regularizer=self.gate_kernel_regularizer,\n",
    "            constraint=self.gate_kernel_constraint\n",
    "        ) for i in range(self.num_tasks)]\n",
    "\n",
    "        # Initialize gate bias (number of experts * number of tasks)\n",
    "        if self.use_gate_bias:\n",
    "            self.gate_bias = [self.add_weight(\n",
    "                name='gate_bias_task_{}'.format(i),\n",
    "                shape=(self.num_experts,),\n",
    "                initializer=self.gate_bias_initializer,\n",
    "                regularizer=self.gate_bias_regularizer,\n",
    "                constraint=self.gate_bias_constraint\n",
    "            ) for i in range(self.num_tasks)]\n",
    "\n",
    "        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dimension})\n",
    "\n",
    "        super(MMoE, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        \"\"\"\n",
    "        Method for the forward function of the layer.\n",
    "        :param inputs: Input tensor\n",
    "        :param kwargs: Additional keyword arguments for the base method\n",
    "        :return: A tensor\n",
    "        \"\"\"\n",
    "        gate_outputs = []\n",
    "        final_outputs = []\n",
    "\n",
    "        # f_{i}(x) = activation(W_{i} * x + b), where activation is ReLU according to the paper\n",
    "        print('inputs:', inputs.shape)\n",
    "        print('expert_kernels:', self.expert_kernels, '\\n','gate_kernels:', self.gate_kernels)\n",
    "        expert_outputs = tf.tensordot(a=inputs, b=self.expert_kernels, axes=1)\n",
    "        # Add the bias term to the expert weights if necessary\n",
    "        if self.use_expert_bias:\n",
    "            expert_outputs = K.bias_add(x=expert_outputs, bias=self.expert_bias)\n",
    "        expert_outputs = self.expert_activation(expert_outputs)\n",
    "        print('expert_outputs', expert_outputs)\n",
    "\n",
    "        # g^{k}(x) = activation(W_{gk} * x + b), where activation is softmax according to the paper\n",
    "        for index, gate_kernel in enumerate(self.gate_kernels):\n",
    "            gate_output = K.dot(x=inputs, y=gate_kernel)\n",
    "            # Add the bias term to the gate weights if necessary\n",
    "            if self.use_gate_bias:\n",
    "                gate_output = K.bias_add(x=gate_output, bias=self.gate_bias[index])\n",
    "            gate_output = self.gate_activation(gate_output)\n",
    "            gate_outputs.append(gate_output)\n",
    "        print('gate_outputs:',gate_outputs)\n",
    "\n",
    "        # f^{k}(x) = sum_{i=1}^{n}(g^{k}(x)_{i} * f_{i}(x))\n",
    "        for gate_output in gate_outputs:\n",
    "            expanded_gate_output = K.expand_dims(gate_output, axis=1)\n",
    "            print('expanded_gate_output:', expanded_gate_output)\n",
    "            weighted_expert_output = expert_outputs * K.repeat_elements(expanded_gate_output, self.units, axis=1)\n",
    "            print('weighted_expert_output:', weighted_expert_output)\n",
    "            final_outputs.append(K.sum(weighted_expert_output, axis=2))\n",
    "            \n",
    "        print('final_outputs:', final_outputs)\n",
    "        return final_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\"\n",
    "        Method for computing the output shape of the MMoE layer.\n",
    "        :param input_shape: Shape tuple (tuple of integers)\n",
    "        :return: List of input shape tuple where the size of the list is equal to the number of tasks\n",
    "        \"\"\"\n",
    "        assert input_shape is not None and len(input_shape) >= 2\n",
    "\n",
    "        output_shape = list(input_shape)\n",
    "        output_shape[-1] = self.units\n",
    "        output_shape = tuple(output_shape)\n",
    "\n",
    "        return [output_shape for _ in range(self.num_tasks)]\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "        Method for returning the configuration of the MMoE layer.\n",
    "        :return: Config dictionary\n",
    "        \"\"\"\n",
    "        config = {\n",
    "            'units': self.units,\n",
    "            'num_experts': self.num_experts,\n",
    "            'num_tasks': self.num_tasks,\n",
    "            'use_expert_bias': self.use_expert_bias,\n",
    "            'use_gate_bias': self.use_gate_bias,\n",
    "            'expert_activation': activations.serialize(self.expert_activation),\n",
    "            'gate_activation': activations.serialize(self.gate_activation),\n",
    "            'expert_bias_initializer': initializers.serialize(self.expert_bias_initializer),\n",
    "            'gate_bias_initializer': initializers.serialize(self.gate_bias_initializer),\n",
    "            'expert_bias_regularizer': regularizers.serialize(self.expert_bias_regularizer),\n",
    "            'gate_bias_regularizer': regularizers.serialize(self.gate_bias_regularizer),\n",
    "            'expert_bias_constraint': constraints.serialize(self.expert_bias_constraint),\n",
    "            'gate_bias_constraint': constraints.serialize(self.gate_bias_constraint),\n",
    "            'expert_kernel_initializer': initializers.serialize(self.expert_kernel_initializer),\n",
    "            'gate_kernel_initializer': initializers.serialize(self.gate_kernel_initializer),\n",
    "            'expert_kernel_regularizer': regularizers.serialize(self.expert_kernel_regularizer),\n",
    "            'gate_kernel_regularizer': regularizers.serialize(self.gate_kernel_regularizer),\n",
    "            'expert_kernel_constraint': constraints.serialize(self.expert_kernel_constraint),\n",
    "            'gate_kernel_constraint': constraints.serialize(self.gate_kernel_constraint),\n",
    "            'activity_regularizer': regularizers.serialize(self.activity_regularizer)\n",
    "        }\n",
    "        base_config = super(MMoE, self).get_config()\n",
    "\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda02002-e149-4678-beab-d3edd86151f5",
   "metadata": {},
   "source": [
    "#### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c5ee9c9-791e-4d3e-8354-776c4c9235eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df <class 'pandas.core.frame.DataFrame'> (199523, 42)\n",
      "other_df <class 'pandas.core.frame.DataFrame'> (99762, 42)\n",
      "Training data shape = (199523, 499)\n",
      "Validation data shape = (49881, 499)\n",
      "Test data shape = (49881, 499)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "train_data, train_label, validation_data, validation_label, test_data, test_label, output_info = data_preparation()\n",
    "num_features = train_data.shape[1]\n",
    "\n",
    "print('Training data shape = {}'.format(train_data.shape))\n",
    "print('Validation data shape = {}'.format(validation_data.shape))\n",
    "print('Test data shape = {}'.format(test_data.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84b5d903-0d26-41c2-a8f0-1ee7b30eb265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: (None, 499)\n",
      "expert_kernels: <tf.Variable 'm_mo_e/expert_kernel:0' shape=(499, 4, 8) dtype=float32> \n",
      " gate_kernels: ListWrapper([<tf.Variable 'm_mo_e/gate_kernel_task_0:0' shape=(499, 8) dtype=float32>, <tf.Variable 'm_mo_e/gate_kernel_task_1:0' shape=(499, 8) dtype=float32>])\n",
      "expert_outputs Tensor(\"m_mo_e/Relu:0\", shape=(None, 4, 8), dtype=float32)\n",
      "gate_outputs: [<tf.Tensor 'm_mo_e/Softmax:0' shape=(None, 8) dtype=float32>, <tf.Tensor 'm_mo_e/Softmax_1:0' shape=(None, 8) dtype=float32>]\n",
      "expanded_gate_output: Tensor(\"m_mo_e/ExpandDims:0\", shape=(None, 1, 8), dtype=float32)\n",
      "weighted_expert_output: Tensor(\"m_mo_e/mul:0\", shape=(None, 4, 8), dtype=float32)\n",
      "expanded_gate_output: Tensor(\"m_mo_e/ExpandDims_1:0\", shape=(None, 1, 8), dtype=float32)\n",
      "weighted_expert_output: Tensor(\"m_mo_e/mul_1:0\", shape=(None, 4, 8), dtype=float32)\n",
      "final_outputs: [<tf.Tensor 'm_mo_e/Sum:0' shape=(None, 4) dtype=float32>, <tf.Tensor 'm_mo_e/Sum_1:0' shape=(None, 4) dtype=float32>]\n",
      "mmoe_layers: 2 [<KerasTensor: shape=(None, 4) dtype=float32 (created by layer 'm_mo_e')>, <KerasTensor: shape=(None, 4) dtype=float32 (created by layer 'm_mo_e')>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 16:41:41.391929: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-9.0/lib64:/usr/local/cuda-9.0/extras/CUPTI/lib64:/usr/local/cuda-8.0/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64:/usr/lib:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/lib:/usr/local/lib:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/lib:/usr/local/lib:/usr/local/cuda-11.0/lib64:/usr/local/cuda-11.0/extras/CUPTI/lib64/:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/lib:/usr/local/lib:/usr/local/cuda-11.0/lib64:/usr/local/cuda-11.0/extras/CUPTI/lib64/:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/lib:/usr/local/lib\n",
      "2022-09-19 16:41:41.391971: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-19 16:41:41.391996: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (9-218-60-11): /proc/driver/nvidia/version does not exist\n",
      "2022-09-19 16:41:41.392161: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Set up the input layer\n",
    "input_layer = Input(shape=(num_features,))\n",
    "# Set up MMoE layer\n",
    "mmoe_layers = MMoE(\n",
    "    units=4,\n",
    "    num_experts=8,\n",
    "    num_tasks=2\n",
    ")(input_layer)\n",
    "print('mmoe_layers:',len(mmoe_layers),mmoe_layers)\n",
    "\n",
    "output_layers = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ca08274-d45a-4b63-b687-14c0647278e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build tower layer from MMoE layer\n",
    "for index, task_layer in enumerate(mmoe_layers):\n",
    "    tower_layer = Dense(\n",
    "        units=8,\n",
    "        activation='relu',\n",
    "        kernel_initializer=VarianceScaling())(task_layer)\n",
    "    output_layer = Dense(\n",
    "        units=output_info[index][0],\n",
    "        name=output_info[index][1],\n",
    "        activation='softmax',\n",
    "        kernel_initializer=VarianceScaling())(tower_layer)\n",
    "    output_layers.append(output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a907f02-f6c5-46e1-a373-748f08e963ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 499)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "m_mo_e (MMoE)                   [(None, 4), (None, 4 24000       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 8)            40          m_mo_e[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 8)            40          m_mo_e[0][1]                     \n",
      "__________________________________________________________________________________________________\n",
      "income (Dense)                  (None, 2)            18          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "marital (Dense)                 (None, 2)            18          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 24,116\n",
      "Trainable params: 24,116\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 16:41:42.889174: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "inputs: (None, 499)\n",
      "expert_kernels: <tf.Variable 'm_mo_e/expert_kernel:0' shape=(499, 4, 8) dtype=float32> \n",
      " gate_kernels: ListWrapper([<tf.Variable 'm_mo_e/gate_kernel_task_0:0' shape=(499, 8) dtype=float32>, <tf.Variable 'm_mo_e/gate_kernel_task_1:0' shape=(499, 8) dtype=float32>])\n",
      "expert_outputs Tensor(\"model/m_mo_e/Relu:0\", shape=(None, 4, 8), dtype=float32)\n",
      "gate_outputs: [<tf.Tensor 'model/m_mo_e/Softmax:0' shape=(None, 8) dtype=float32>, <tf.Tensor 'model/m_mo_e/Softmax_1:0' shape=(None, 8) dtype=float32>]\n",
      "expanded_gate_output: Tensor(\"model/m_mo_e/ExpandDims:0\", shape=(None, 1, 8), dtype=float32)\n",
      "weighted_expert_output: Tensor(\"model/m_mo_e/mul:0\", shape=(None, 4, 8), dtype=float32)\n",
      "expanded_gate_output: Tensor(\"model/m_mo_e/ExpandDims_1:0\", shape=(None, 1, 8), dtype=float32)\n",
      "weighted_expert_output: Tensor(\"model/m_mo_e/mul_1:0\", shape=(None, 4, 8), dtype=float32)\n",
      "final_outputs: [<tf.Tensor 'model/m_mo_e/Sum:0' shape=(None, 4) dtype=float32>, <tf.Tensor 'model/m_mo_e/Sum_1:0' shape=(None, 4) dtype=float32>]\n",
      "inputs: (None, 499)\n",
      "expert_kernels: <tf.Variable 'm_mo_e/expert_kernel:0' shape=(499, 4, 8) dtype=float32> \n",
      " gate_kernels: ListWrapper([<tf.Variable 'm_mo_e/gate_kernel_task_0:0' shape=(499, 8) dtype=float32>, <tf.Variable 'm_mo_e/gate_kernel_task_1:0' shape=(499, 8) dtype=float32>])\n",
      "expert_outputs Tensor(\"model/m_mo_e/Relu:0\", shape=(None, 4, 8), dtype=float32)\n",
      "gate_outputs: [<tf.Tensor 'model/m_mo_e/Softmax:0' shape=(None, 8) dtype=float32>, <tf.Tensor 'model/m_mo_e/Softmax_1:0' shape=(None, 8) dtype=float32>]\n",
      "expanded_gate_output: Tensor(\"model/m_mo_e/ExpandDims:0\", shape=(None, 1, 8), dtype=float32)\n",
      "weighted_expert_output: Tensor(\"model/m_mo_e/mul:0\", shape=(None, 4, 8), dtype=float32)\n",
      "expanded_gate_output: Tensor(\"model/m_mo_e/ExpandDims_1:0\", shape=(None, 1, 8), dtype=float32)\n",
      "weighted_expert_output: Tensor(\"model/m_mo_e/mul_1:0\", shape=(None, 4, 8), dtype=float32)\n",
      "final_outputs: [<tf.Tensor 'model/m_mo_e/Sum:0' shape=(None, 4) dtype=float32>, <tf.Tensor 'model/m_mo_e/Sum_1:0' shape=(None, 4) dtype=float32>]\n",
      "6210/6236 [============================>.] - ETA: 0s - loss: 0.4800 - income_loss: 0.1836 - marital_loss: 0.2963 - income_accuracy: 0.9378 - marital_accuracy: 0.8855inputs: (None, 499)\n",
      "expert_kernels: <tf.Variable 'm_mo_e/expert_kernel:0' shape=(499, 4, 8) dtype=float32> \n",
      " gate_kernels: ListWrapper([<tf.Variable 'm_mo_e/gate_kernel_task_0:0' shape=(499, 8) dtype=float32>, <tf.Variable 'm_mo_e/gate_kernel_task_1:0' shape=(499, 8) dtype=float32>])\n",
      "expert_outputs Tensor(\"model/m_mo_e/Relu:0\", shape=(None, 4, 8), dtype=float32)\n",
      "gate_outputs: [<tf.Tensor 'model/m_mo_e/Softmax:0' shape=(None, 8) dtype=float32>, <tf.Tensor 'model/m_mo_e/Softmax_1:0' shape=(None, 8) dtype=float32>]\n",
      "expanded_gate_output: Tensor(\"model/m_mo_e/ExpandDims:0\", shape=(None, 1, 8), dtype=float32)\n",
      "weighted_expert_output: Tensor(\"model/m_mo_e/mul:0\", shape=(None, 4, 8), dtype=float32)\n",
      "expanded_gate_output: Tensor(\"model/m_mo_e/ExpandDims_1:0\", shape=(None, 1, 8), dtype=float32)\n",
      "weighted_expert_output: Tensor(\"model/m_mo_e/mul_1:0\", shape=(None, 4, 8), dtype=float32)\n",
      "final_outputs: [<tf.Tensor 'model/m_mo_e/Sum:0' shape=(None, 4) dtype=float32>, <tf.Tensor 'model/m_mo_e/Sum_1:0' shape=(None, 4) dtype=float32>]\n",
      "6236/6236 [==============================] - 14s 2ms/step - loss: 0.4794 - income_loss: 0.1835 - marital_loss: 0.2959 - income_accuracy: 0.9378 - marital_accuracy: 0.8857 - val_loss: 0.3786 - val_income_loss: 0.1601 - val_marital_loss: 0.2184 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9168\n",
      "inputs: (None, 499)\n",
      "expert_kernels: <tf.Variable 'm_mo_e/expert_kernel:0' shape=(499, 4, 8) dtype=float32> \n",
      " gate_kernels: ListWrapper([<tf.Variable 'm_mo_e/gate_kernel_task_0:0' shape=(499, 8) dtype=float32>, <tf.Variable 'm_mo_e/gate_kernel_task_1:0' shape=(499, 8) dtype=float32>])\n",
      "expert_outputs Tensor(\"model/m_mo_e/Relu:0\", shape=(None, 4, 8), dtype=float32)\n",
      "gate_outputs: [<tf.Tensor 'model/m_mo_e/Softmax:0' shape=(None, 8) dtype=float32>, <tf.Tensor 'model/m_mo_e/Softmax_1:0' shape=(None, 8) dtype=float32>]\n",
      "expanded_gate_output: Tensor(\"model/m_mo_e/ExpandDims:0\", shape=(None, 1, 8), dtype=float32)\n",
      "weighted_expert_output: Tensor(\"model/m_mo_e/mul:0\", shape=(None, 4, 8), dtype=float32)\n",
      "expanded_gate_output: Tensor(\"model/m_mo_e/ExpandDims_1:0\", shape=(None, 1, 8), dtype=float32)\n",
      "weighted_expert_output: Tensor(\"model/m_mo_e/mul_1:0\", shape=(None, 4, 8), dtype=float32)\n",
      "final_outputs: [<tf.Tensor 'model/m_mo_e/Sum:0' shape=(None, 4) dtype=float32>, <tf.Tensor 'model/m_mo_e/Sum_1:0' shape=(None, 4) dtype=float32>]\n",
      "ROC-AUC-income-Train: 0.9086 ROC-AUC-income-Validation: 0.909 ROC-AUC-income-Test: 0.9087\n",
      "ROC-AUC-marital-Train: 0.9651 ROC-AUC-marital-Validation: 0.9556 ROC-AUC-marital-Test: 0.9574\n",
      "Epoch 2/3\n",
      "6236/6236 [==============================] - 12s 2ms/step - loss: 0.3028 - income_loss: 0.1532 - marital_loss: 0.1496 - income_accuracy: 0.9379 - marital_accuracy: 0.9419 - val_loss: 0.3622 - val_income_loss: 0.1527 - val_marital_loss: 0.2095 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9162\n",
      "ROC-AUC-income-Train: 0.9134 ROC-AUC-income-Validation: 0.9113 ROC-AUC-income-Test: 0.9112\n",
      "ROC-AUC-marital-Train: 0.9872 ROC-AUC-marital-Validation: 0.9716 ROC-AUC-marital-Test: 0.9712\n",
      "Epoch 3/3\n",
      "6236/6236 [==============================] - 11s 2ms/step - loss: 0.2823 - income_loss: 0.1509 - marital_loss: 0.1314 - income_accuracy: 0.9379 - marital_accuracy: 0.9450 - val_loss: 0.3788 - val_income_loss: 0.1732 - val_marital_loss: 0.2056 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9166\n",
      "ROC-AUC-income-Train: 0.917 ROC-AUC-income-Validation: 0.9142 ROC-AUC-income-Test: 0.9132\n",
      "ROC-AUC-marital-Train: 0.9901 ROC-AUC-marital-Validation: 0.9736 ROC-AUC-marital-Test: 0.9729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3480157ed0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile model\n",
    "model = Model(inputs=[input_layer], outputs=output_layers)\n",
    "adam_optimizer = Adam()\n",
    "model.compile(\n",
    "    loss={'income': 'binary_crossentropy', 'marital': 'binary_crossentropy'},\n",
    "    optimizer=adam_optimizer,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "# Print out model architecture summary\n",
    "model.summary()\n",
    "# Train the model\n",
    "model.fit(\n",
    "    x=train_data,\n",
    "    y=train_label,\n",
    "    validation_data=(validation_data, validation_label),\n",
    "    callbacks=[\n",
    "        ROCCallback(\n",
    "            training_data=(train_data, train_label),\n",
    "            validation_data=(validation_data, validation_label),\n",
    "            test_data=(test_data, test_label)\n",
    "        )\n",
    "    ],\n",
    "    epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426bb6af-3f24-45bd-a742-5f5a7342d49f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594ae674-f838-477a-b31f-41a23faab7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe5fc0f-9253-4ba2-8bb0-f829da796bef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_tf26_cpu",
   "language": "python",
   "name": "py37_tf26_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
