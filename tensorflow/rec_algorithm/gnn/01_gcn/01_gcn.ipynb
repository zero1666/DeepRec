{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cad12a2-4299-482a-aea2-c984965fa760",
   "metadata": {},
   "source": [
    "## Graph Convolutional Network（GCN）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed9e54f-fabb-4159-8a03-86620a1587c3",
   "metadata": {},
   "source": [
    "### Reference\n",
    "1. [图卷积神经网络(GCN)理解与tensorflow2.0代码实现](https://github.com/zxxwin/tf2_gcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ded197ce-9adf-4e93-9305-b0e8d74f366e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e3b2c60-9aa3-4a4f-8293-722e68613521",
   "metadata": {},
   "source": [
    "## 1. Cora数据集合\n",
    "Cora数据集由机器学习论文组成，是近年来图深度学习很喜欢使用的数据集。\n",
    "整个数据集有2708篇论文，所有样本点被分为7个类别，\n",
    "类别分别是\n",
    "+ 1）基于案例；\n",
    "+ 2）遗传算法；\n",
    "+ 3）神经网络；\n",
    "+ 4）概率方法；\n",
    "+ 5）强化学习；\n",
    "+ 6）规则学习；\n",
    "+ 7）理论。\n",
    "\n",
    "每篇论文都由一个1433维的词向量表示，所以，每个样本点具有1433个特征。词向量的每个元素都对应一个词，且该元素只有0或1两个取值。取0表示该元素对应的词不在论文中，取1表示在论文中。\n",
    "\n",
    "\n",
    "数据下载链接：https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz\n",
    "\n",
    "Reference: [cora数据集的读取和处理](https://blog.csdn.net/weixin_41650348/article/details/109406230)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21a8efde-bf45-4808-b7e3-2c5b92edac38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10078.38s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-07-08 19:01:39--  https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz\n",
      "Resolving linqs-data.soe.ucsc.edu (linqs-data.soe.ucsc.edu)... 128.114.47.74\n",
      "Connecting to linqs-data.soe.ucsc.edu (linqs-data.soe.ucsc.edu)|128.114.47.74|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 168052 (164K) [application/x-gzip]\n",
      "Saving to: ‘cora.tgz’\n",
      "\n",
      "100%[======================================>] 168,052      141KB/s   in 1.2s   \n",
      "\n",
      "2022-07-08 19:01:41 (141 KB/s) - ‘cora.tgz’ saved [168052/168052]\n",
      "\n",
      "cora/\n",
      "cora/README\n",
      "cora/cora.cites\n",
      "cora/cora.content\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10086.30s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/user_code/davidwwang/workspace/tensorflow/gnn\n"
     ]
    }
   ],
   "source": [
    "!cd ../../data;wget https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz;tar -zxvf cora.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bae7130-5243-4e26-b8b9-cf086392a3a8",
   "metadata": {},
   "source": [
    "###### 数据集查看\n",
    "下载的压缩包中有三个文件，分别是cora.cites，cora.content，README。\n",
    "\n",
    "+ README是对数据集的介绍；\n",
    "+ cora.content是所有论文的独自的信息；\n",
    "cora.content共有2708行，每一行代表一个样本点，即一篇论文。每一行由三部分组成，分别是论文的编号，如31336；论文的词向量，一个有1433位的二进制；论文的类别，如Neural_Networks。\n",
    "+ cora.cites是论文之间的引用记录。\n",
    "cora.cites共5429行， 每一行有两个论文编号，表示第一个编号的论文先写，第二个编号的论文引用第一个编号的论文。如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71f064b6-22e4-4a8f-ab89-aa63281b2ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2708, 1435)\n",
      "      0     1     2     3     4     5     6     7     8     9     ...  1425  \\\n",
      "0    31336     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "1  1061127     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "2  1106406     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "\n",
      "   1426  1427  1428  1429  1430  1431  1432  1433                    1434  \n",
      "0     0     1     0     0     0     0     0     0         Neural_Networks  \n",
      "1     1     0     0     0     0     0     0     0           Rule_Learning  \n",
      "2     0     0     0     0     0     0     0     0  Reinforcement_Learning  \n",
      "\n",
      "[3 rows x 1435 columns]\n",
      "(5429, 2)\n",
      "    0       1\n",
      "0  35    1033\n",
      "1  35  103482\n",
      "2  35  103515\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 读取.content 文件\n",
    "cora_content = pd.read_csv('../../data/cora/cora.content', sep='\\t', header=None)\n",
    "# 查看数据初始格式\n",
    "print(cora_content.shape)\n",
    "print(cora_content.head(3))\n",
    "\n",
    "# 读取 .cites文件\n",
    "cora_cites = pd.read_csv('../../data/cora/cora.cites', sep='\\t', header=None)\n",
    "print(cora_cites.shape)\n",
    "print(cora_cites.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d46715e-b1ec-4e21-9be2-340e03da9533",
   "metadata": {},
   "source": [
    "建立从paper_id到[0,2707]数字间的映射函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ec71dc8-a2b7-43e1-a100-a3a5ca2e05c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_idx=list(cora_content.index) #将索引制作成列表\n",
    "paper_id = list(cora_content.iloc[:,0])#将content第一列取出\n",
    "mp = dict(zip(paper_id, content_idx))#映射成{论文id:索引编号}的字典形式\n",
    "#查看某个论文id对应的索引编号\n",
    "mp[31336]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abaf5e5-b3ef-45f2-9b9d-dc96ce2041d8",
   "metadata": {},
   "source": [
    "提取feature matrix（2708，1433）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bdce040-b8ee-4ab4-9561-da9f40ef9ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2708, 1433)\n",
      "   1     2     3     4     5     6     7     8     9     10    ...  1424  \\\n",
      "0     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "1     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "2     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "\n",
      "   1425  1426  1427  1428  1429  1430  1431  1432  1433  \n",
      "0     0     0     1     0     0     0     0     0     0  \n",
      "1     0     1     0     0     0     0     0     0     0  \n",
      "2     0     0     0     0     0     0     0     0     0  \n",
      "\n",
      "[3 rows x 1433 columns]\n"
     ]
    }
   ],
   "source": [
    "#切片提取从第一列到倒数第二列（左闭右开）\n",
    "feature = cora_content.iloc[:,1:-1]\n",
    "print(feature.shape)\n",
    "print(feature.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd978d9-5bc1-4ad6-acea-cadb06c5b55e",
   "metadata": {},
   "source": [
    "标签进行one-hot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cbe47a0-8844-49ef-bf3d-838da6ad078f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_Based</th>\n",
       "      <th>Genetic_Algorithms</th>\n",
       "      <th>Neural_Networks</th>\n",
       "      <th>Probabilistic_Methods</th>\n",
       "      <th>Reinforcement_Learning</th>\n",
       "      <th>Rule_Learning</th>\n",
       "      <th>Theory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Case_Based  Genetic_Algorithms  Neural_Networks  Probabilistic_Methods  \\\n",
       "0           0                   0                1                      0   \n",
       "1           0                   0                0                      0   \n",
       "2           0                   0                0                      0   \n",
       "\n",
       "   Reinforcement_Learning  Rule_Learning  Theory  \n",
       "0                       0              0       0  \n",
       "1                       0              1       0  \n",
       "2                       1              0       0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = cora_content.iloc[:, -1]\n",
    "label = pd.get_dummies(label) # 读热编码\n",
    "label.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad8aa2d-d00f-46fe-b9aa-762b7f0ba6ed",
   "metadata": {},
   "source": [
    "创建adjacent matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cdd5b65-c70e-4f59-ba34-99c007688d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2708,)\n",
      "10556.0\n"
     ]
    }
   ],
   "source": [
    "mat_size = cora_content.shape[0] #第一维的大小2708就是邻接矩阵的规模\n",
    "adj_mat = np.zeros((mat_size, mat_size)) #创建0矩阵\n",
    "for i, j in zip(cora_cites[0], cora_cites[1]): #枚举形式（u，v）\n",
    "    x = mp[i]\n",
    "    y = mp[j]\n",
    "    adj_mat[x][y]=adj_mat[y][x]=1\n",
    "\n",
    "print(sum(adj_mat).shape)\n",
    "print(sum(sum(adj_mat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838b37a1-fc72-4c6d-95da-8710b3bba255",
   "metadata": {},
   "source": [
    "如果需要后续转为numpy或者其他形式（之前一直使用pandas的dataframe格式）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5dd608f5-9f8e-4c13-93f5-d9e8f1a610a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#转换为numpy格式的数据\n",
    "feature = np.array(feature)\n",
    "label = np.array(label)\n",
    "adj_mat =np.array(adj_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c726a913-34c2-49f4-8cd7-b8164032fd5b",
   "metadata": {},
   "source": [
    "## 2. GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "604bac91-f317-4297-a45b-0af065ebb83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import scipy.sparse as sp\n",
    "from time import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97201b5a-cd14-43f5-bf63-e1d0f13e490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在深度学习中往往利用easydict建立一个全局的变量, 这里记录相关的参数配置\n",
    "from easydict import EasyDict\n",
    "config = {\n",
    "    'dataset':'cora',\n",
    "    'hidden1':16,\n",
    "    'epochs':2,\n",
    "    'early_stopping':20,\n",
    "    'weight_decay':5e-4,\n",
    "    'learning_rate': 0.01,\n",
    "    'dropout':0.,\n",
    "    'verbose':False,\n",
    "    'logging':False,\n",
    "    'gpu_id':None\n",
    "}\n",
    "FLAGS = EasyDict(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a79c9d4-e1eb-4150-8ca6-65ba42873fb3",
   "metadata": {},
   "source": [
    "读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47506030-11a3-40e2-a731-4c1bcb121f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def load_data_planetoid(dataset):\n",
    "    keys ={'x', 'y', 'tx','ty','allx', 'ally', 'graph'} # 文件名后缀\n",
    "    # print(type(keys))\n",
    "    objects = defaultdict() # 带默认值的dict\n",
    "    # print(objects)\n",
    "    for key in keys:\n",
    "        with open('data_split/ind.{}.{}'.format(dataset, key), 'rb') as f:\n",
    "            objects[key]=pickle.load(f, encoding='latin1')\n",
    "            # print(key, \"  \", type(objects[key]))\n",
    "    \n",
    "    check_x = objects['x'].toarray()\n",
    "    # print(\"allx \", objects['allx'].toarray().shape)\n",
    "    # print(\"tx \", objects['tx'].toarray().shape)\n",
    "    # print(\"x \", check_x.shape, '\\n', check_x[0:3,:])\n",
    "    # print(\"ally \", objects['ally'].shape)\n",
    "    # print(\"ty \", objects['ty'].shape)\n",
    "    # print(\"y \", objects['y'].shape, '\\n', objects['y'][0:3,:])\n",
    "    # print(\"graph \",len(objects['graph']), objects['graph'][0])\n",
    "    \n",
    "    test_index = [int(x) for x in open('data_split/ind.{}.test.index'.format(dataset))]\n",
    "    # print('test_index', type(test_index), len(test_index), test_index[:3])\n",
    "    test_index_sort = np.sort(test_index)\n",
    "    # print('test_index_sort', test_index_sort[0:5])\n",
    "    G = nx.from_dict_of_lists(objects['graph'])\n",
    "    \n",
    "    A_mat = nx.adjacency_matrix(G)\n",
    "    # print('A_mat', type(A_mat), A_mat.toarray().shape, '\\n', A_mat.toarray()[0:3,:])\n",
    "    X_mat = sp.vstack((objects['allx'], objects['tx'])).tolil()\n",
    "    # print('X_mat', type(X_mat), X_mat.toarray().shape, '\\n', X_mat.toarray()[0:3,:])\n",
    "    # 把特征矩阵还原，和对应的邻接矩阵对应起来，因为之前是打乱的，不对齐的话，特征就和对应的节点搞错了。\n",
    "    X_mat[test_index, :] = X_mat[test_index_sort,:]\n",
    "    z_vec = np.vstack((objects['ally'], objects['ty']))\n",
    "    # print(type(z_vec), z_vec.shape, '\\n', z_vec[0:3,:])\n",
    "\n",
    "    z_vec[test_index, :] = z_vec[test_index_sort, :]\n",
    "    z_vec = z_vec.argmax(1)\n",
    "    # print('z_vec', type(z_vec),  '\\n', z_vec.shape, z_vec[0:3])\n",
    "\n",
    "    \n",
    "    train_idx = range(len(objects['y']))\n",
    "    val_idx = range(len(objects['y']), len(objects['y']) + 500)\n",
    "    test_idx = test_index_sort.tolist()\n",
    "    # print('train_idx ', len(train_idx), train_idx)\n",
    "    # print('val_idx ', len(val_idx), val_idx)\n",
    "    # print('test_idx ', len(test_idx))\n",
    "\n",
    "    return A_mat, X_mat, z_vec, train_idx, val_idx, test_idx\n",
    "\n",
    "cora_data = load_data_planetoid(FLAGS.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347b3491-5550-4d0b-a210-270db7e07a51",
   "metadata": {},
   "source": [
    "处理稀疏矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5637ba77-84cb-4b11-8c07-87ff75ceb94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 稀疏矩阵的 dropout\n",
    "def sparse_dropout(x, dropout_rate, noise_shape):\n",
    "    # print('dropout', x.shape, 'rate', dropout_rate, 'noise', (noise_shape))\n",
    "    \n",
    "    random_tensor = 1 - dropout_rate\n",
    "    random_tensor += tf.random.uniform(noise_shape)\n",
    "    dropout_mask = tf.cast(tf.floor(random_tensor), dtype=tf.bool)\n",
    "    # 从稀疏矩阵中取出dropout_mask对应的元素\n",
    "    pre_out = tf.sparse.retain(x, dropout_mask)\n",
    "    \n",
    "    \n",
    "    return pre_out * (1. / (1 - dropout_rate))\n",
    "    \n",
    "# 稀疏矩阵转稀疏张量\n",
    "def sp_matrix_to_sp_tensor(M):\n",
    "    # print('M', type(M), M.shape)\n",
    "    if not isinstance(M, sp.csr.csr_matrix):\n",
    "        M = M.tocsr()\n",
    "    # 获取非0元素坐标\n",
    "    row, col = M.nonzero()\n",
    "    # SparseTensor 参数： 二维坐标数组，数据，形状\n",
    "    X = tf.SparseTensor(np.mat([row, col]).T, M.data, M.shape)\n",
    "    X = tf.cast(X, tf.float32)\n",
    "    # print('X', type(X), X.shape)\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28e2294-b50a-4ffd-acec-40f3ea10f499",
   "metadata": {},
   "source": [
    "定义图卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b692051-c9a0-4a68-bc02-46d5de4cb800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import activations, regularizers, constraints, initializers\n",
    "\n",
    "class GCNConv(tf.keras.layers.Layer):\n",
    "    def __init__( self,\n",
    "                 units,\n",
    "                 activation=lambda x:x,\n",
    "                 use_bias = True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 **kwargs):\n",
    "        \n",
    "        super(GCNConv, self).__init__()\n",
    "        \n",
    "        self.units = units\n",
    "        self.activation = activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "        self.kernel_initializer=initializers.get(kernel_initializer)\n",
    "        self.bias_initializer=initializers.get(bias_initializer)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \"\"\"GCN has two inputs : [shape(An), shape(X)]\n",
    "        \"\"\"\n",
    "        fdim = input_shape[1][1] #feature dim\n",
    "        # print('input_shape', type(input_shape), input_shape, fdim, self.units)\n",
    "        # 初始化权重矩阵\n",
    "        self.weight = self.add_weight(name='weight',\n",
    "                                     shape=(fdim, self.units),\n",
    "                                     initializer= self.kernel_initializer,\n",
    "                                     trainable=True)\n",
    "        if self.use_bias:\n",
    "            # 初始化偏置项目\n",
    "            self.bias = self.add_weight(name='bias',\n",
    "                                       shape=(self.units, ),\n",
    "                                       initializer = self.bias_initializer,\n",
    "                                       trainable=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \"\"\" GCN has two inputs : [An, X]\n",
    "        \"\"\"\n",
    "        self.An = inputs[0]\n",
    "        self.X = inputs[1]\n",
    "        # print('An', type(self.An), self.An.shape)\n",
    "        # print('X', type(self.X), self.X.shape)\n",
    "        # print('W', type(self.weight), self.weight.shape)\n",
    "\n",
    "        \n",
    "        # 计算XW\n",
    "        if isinstance(self.X, tf.SparseTensor):\n",
    "            h = tf.sparse.sparse_dense_matmul(self.X, self.weight)\n",
    "        else:\n",
    "            h = tf.matmul(self.X, self.weight)\n",
    "        # 计算AxW\n",
    "        # print('h', type(h), h.shape)\n",
    "        output = tf.sparse.sparse_dense_matmul(self.An, h)\n",
    "        # print('bias', type(self.bias), self.bias.shape)\n",
    "        \n",
    "        if self.use_bias:\n",
    "            output = tf.nn.bias_add(output, self.bias)\n",
    "        \n",
    "        if self.activation:\n",
    "            output = self.activation(output)\n",
    "        \n",
    "        # print('output', type(output), output.shape)\n",
    "        return output\n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea6130d-b3bb-4e51-b3f8-eda47137c9c7",
   "metadata": {},
   "source": [
    "定义GCN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d5cf35dd-bee3-405b-bc3e-bb5bf880a601",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "class GCN():\n",
    "    def __init__(self, An, X, sizes, **kwargs):\n",
    "        self.with_relu = True\n",
    "        self.with_bias = True\n",
    "        \n",
    "        self.lr = FLAGS.learning_rate\n",
    "        self.dropout = FLAGS.dropout\n",
    "        self.verbose = FLAGS.verbose\n",
    "        \n",
    "        self.An = An\n",
    "        self.X = X\n",
    "        self.layer_sizes = sizes\n",
    "        self.shape = An.shape\n",
    "        \n",
    "        self.An_tf = sp_matrix_to_sp_tensor(self.An)\n",
    "        self.X_tf = sp_matrix_to_sp_tensor(self.X)\n",
    "        \n",
    "        self.layer1 = GCNConv(self.layer_sizes[0], activation='relu')\n",
    "        self.layer2 = GCNConv(self.layer_sizes[1])\n",
    "        self.opt = tf.optimizers.Adam(learning_rate = self.lr)\n",
    "        \n",
    "    def train(self, idx_train, labels_train, idx_val, label_val):\n",
    "        # print(len(idx_train), labels_train.shape, len(idx_val), label_val.shape)\n",
    "        # print(idx_train, labels_train, len(idx_val), label_val)\n",
    "\n",
    "        K = labels_train.max() + 1\n",
    "        print(K)\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        # use adam to optimize\n",
    "        for it in range(FLAGS.epochs):\n",
    "            tic = time()\n",
    "            with tf.GradientTape() as tape:\n",
    "                _loss = self.loss_fn(idx_train, np.eye(K)[labels_train])\n",
    "            # optimize over weights\n",
    "            grad_list = tape.gradient(_loss, self.var_list)\n",
    "            grads_and_vars = zip(grad_list, self.var_list)\n",
    "            self.opt.apply_gradients(grads_and_vars)\n",
    "            \n",
    "            # evaluate on the training\n",
    "            train_loss, train_acc = self.evaluate(idx_train, labels_train, training=True)\n",
    "            train_losses.append(train_loss)\n",
    "            val_loss, val_acc = self.evaluate(idx_val, label_val, training=False)\n",
    "            val_losses.append(val_loss)\n",
    "            toc =time()\n",
    "            if self.verbose:\n",
    "                print(\"iter:{:03d}\".format(it),\n",
    "                      \"train_loss:{:.4f}\".format(train_loss),\n",
    "                      \"train_acc:{:.4f}\".format(train_acc),\n",
    "                      \"val_loss:{:.4f}\".format(val_loss),\n",
    "                      \"val_acc:{:.4f}\".format(val_acc),\n",
    "                      \"time:{:.4f}\".format(toc - tic))\n",
    "            \n",
    "        return train_losses\n",
    "    \n",
    "    def loss_fn(self, idx, labels, training=True):\n",
    "        if training:\n",
    "            # .nnz 是获得X中元素的个数\n",
    "            _X = sparse_dropout(self.X_tf, self.dropout, [self.X.nnz])\n",
    "        else:\n",
    "            _X = self.X_tf\n",
    "            \n",
    "        self.h1 = self.layer1([self.An_tf,_X])\n",
    "        if training:\n",
    "            _h1 = tf.nn.dropout(self.h1, self.dropout)\n",
    "        else:\n",
    "            _h1 = self.h1\n",
    "        \n",
    "        self.h2 = self.layer2([self.An_tf, _h1])\n",
    "        print('h2', self.h2.shape)\n",
    "        print('idx', len(idx))\n",
    "        self.var_list = self.layer1.weights + self.layer2.weights\n",
    "        # calculate the loss base on idx and labels\n",
    "        _logits = tf.gather(self.h2, idx)\n",
    "        # print('logit', _logits.shape)\n",
    "        _loss_per_node = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=_logits)\n",
    "         #print('_loss_per_node', _loss_per_node.shape)\n",
    "\n",
    "        _loss = tf.reduce_mean(_loss_per_node)\n",
    "        print\n",
    "        # 加上L2正则项\n",
    "        _loss +=FLAGS.weight_decay * sum(map(tf.nn.l2_loss, self.layer1.weights))\n",
    "        # print('_loss', _loss)\n",
    "        return _loss\n",
    "    \n",
    "    def evaluate(self, idx, true_labels, training):\n",
    "        K = true_labels.max() +1\n",
    "        _loss = self.loss_fn(idx, np.eye(K)[true_labels], training=training).numpy()\n",
    "        _pred_logits = tf.gather(self.h2, idx)\n",
    "        _pred_labels = tf.argmax(_pred_logits, axis=1).numpy()\n",
    "        _acc = accuracy_score(_pred_labels, true_labels)\n",
    "        \n",
    "        return _loss, _acc\n",
    "    \n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a4626e-ef6d-4e77-b8a8-bb32b3560ab0",
   "metadata": {},
   "source": [
    "计算标准化的邻接矩阵：根号D * A * 根号D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f9f807b2-04e5-4afa-b55b-7919addcd4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算标准化的邻接矩阵：根号D * A * 根号D\n",
    "def preprocess_graph(adj):\n",
    "    # print('adj ', adj.shape, type(adj))\n",
    "    # _A = A+I\n",
    "    _adj = adj + sp.eye(adj.shape[0])\n",
    "    # _dseq: 各个节点的度构成的列表\n",
    "    _dseq = _adj.sum(1).A1\n",
    "    # print(type(_dseq), _dseq.shape)\n",
    "    # 构造开根号的度矩阵\n",
    "    _D_half = sp.diags(np.power(_dseq, -0.5))\n",
    "    # 计算标准化的邻接矩阵, @ 表示矩阵乘法\n",
    "    adj_normalized = _D_half @ _adj @ _D_half\n",
    "    return adj_normalized.tocsr()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5d201f86-541e-447e-bb29-578e9c8fccdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An_mat (2708, 2708)\n",
      "7\n",
      "7\n",
      "h2 (2708, 7)\n",
      "idx 140\n",
      "logit (140, 7)\n",
      "_loss_per_node (140,)\n",
      "_loss tf.Tensor(1.9627378, shape=(), dtype=float32)\n",
      "h2 (2708, 7)\n",
      "idx 140\n",
      "logit (140, 7)\n",
      "_loss_per_node (140,)\n",
      "_loss tf.Tensor(1.86438, shape=(), dtype=float32)\n",
      "h2 (2708, 7)\n",
      "idx 500\n",
      "logit (500, 7)\n",
      "_loss_per_node (500,)\n",
      "_loss tf.Tensor(1.9248261, shape=(), dtype=float32)\n",
      "h2 (2708, 7)\n",
      "idx 140\n",
      "logit (140, 7)\n",
      "_loss_per_node (140,)\n",
      "_loss tf.Tensor(1.86438, shape=(), dtype=float32)\n",
      "h2 (2708, 7)\n",
      "idx 140\n",
      "logit (140, 7)\n",
      "_loss_per_node (140,)\n",
      "_loss tf.Tensor(1.7453369, shape=(), dtype=float32)\n",
      "h2 (2708, 7)\n",
      "idx 500\n",
      "logit (500, 7)\n",
      "_loss_per_node (500,)\n",
      "_loss tf.Tensor(1.8768542, shape=(), dtype=float32)\n",
      "h2 (2708, 7)\n",
      "idx 1000\n",
      "logit (1000, 7)\n",
      "_loss_per_node (1000,)\n",
      "_loss tf.Tensor(1.87412, shape=(), dtype=float32)\n",
      "Dataset cora Test loss 1.8741 test acc 0.3250\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 读取数据\n",
    "    # A_mat：邻接矩阵\n",
    "    # X_mat：特征矩阵\n",
    "    # z_vec：label\n",
    "    # train_idx,val_idx,test_idx: 要使用的节点序号\n",
    "    A_mat, X_mat, z_vec, train_idx, val_idx, test_idx = load_data_planetoid(FLAGS.dataset)\n",
    "    # 邻居矩阵标准化\n",
    "    An_mat = preprocess_graph(A_mat)\n",
    "    print('An_mat', An_mat.shape)\n",
    "    # 节点的类别个数\n",
    "    K = z_vec.max() + 1\n",
    "    print(K)\n",
    "    # 构造GCN模型\n",
    "    gcn = GCN(An_mat, X_mat, [FLAGS.hidden1, K])\n",
    "    # 训练\n",
    "    gcn.train(train_idx, z_vec[train_idx], val_idx, z_vec[val_idx])\n",
    "    # 测试\n",
    "    test_res = gcn.evaluate(test_idx, z_vec[test_idx], training=False)\n",
    "    print(\"Dataset {}\".format(FLAGS.dataset),\n",
    "          \"Test loss {:.4f}\".format(test_res[0]),\n",
    "          \"test acc {:.4f}\".format(test_res[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90aff27-01d8-4e24-a543-5870edfe1f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b3aa35-3791-4a4c-9898-9b1651d190ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e06b15c-ab2d-471b-b494-ba3109436607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_tf26_cpu",
   "language": "python",
   "name": "py37_tf26_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
